{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede047dd",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb6a2f",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3418dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "EXISTtraining = pd.read_csv('EXISTtraining_preprocessed.csv')\n",
    "\n",
    "print(EXISTtraining.head())\n",
    "\n",
    "print(EXISTtraining.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f772e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "EXISTtesting = pd.read_csv('EXISTtesting_preprocessed.csv')\n",
    "\n",
    "print(EXISTtesting.head())\n",
    "\n",
    "print(EXISTtesting.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55296a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3522aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)  # Consider tuning this parameter\n",
    "X_train = vectorizer.fit_transform(EXISTtraining['lemmatized_text'])\n",
    "X_test = vectorizer.transform(EXISTtesting['lemmatized_text'])\n",
    "\n",
    "y_train_task1 = EXISTtraining['task1']\n",
    "y_test_task1 = EXISTtesting['task1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb69663",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_task1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier_task1.fit(X_train, y_train_task1)\n",
    "\n",
    "y_pred_task1 = rf_classifier_task1.predict(X_test)\n",
    "\n",
    "print(\"Classification Report for Task 1:\")\n",
    "print(classification_report(y_test_task1, y_pred_task1))\n",
    "print(\"Accuracy for Task 1:\", accuracy_score(y_test_task1, y_pred_task1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d5c69",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add55510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_task2 = EXISTtraining[EXISTtraining['task1'] == 'sexist']\n",
    "test_df_task2 = EXISTtesting[EXISTtesting['task1'] == 'sexist']\n",
    "\n",
    "X_train_task2 = vectorizer.transform(train_df_task2['lemmatized_text']).toarray()\n",
    "X_test_task2 = vectorizer.transform(test_df_task2['lemmatized_text']).toarray()\n",
    "\n",
    "y_train_task2 = train_df_task2['task2']\n",
    "y_test_task2 = test_df_task2['task2']\n",
    "\n",
    "rf_classifier_task2 = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_classifier_task2.fit(X_train_task2, y_train_task2)\n",
    "# Predict on the test set for Task 2\n",
    "y_pred_task2 = rf_classifier_task2.predict(X_test_task2)\n",
    "\n",
    "print(\"Classification Report for Task 2:\")\n",
    "print(classification_report(y_test_task2, y_pred_task2))\n",
    "print(\"Accuracy for Task 2:\", accuracy_score(y_test_task2, y_pred_task2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd050e10",
   "metadata": {},
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ca7d9",
   "metadata": {},
   "source": [
    "## 1st attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71aa500",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005341ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000  # Vocabulary size\n",
    "max_length = 50     # Maximum length of the sequence\n",
    "embedding_dim = 64  # Dimensionality of the embedding vector\n",
    "oov_tok = \"<OOV>\"   # Out of vocabulary token\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(EXISTtraining['lemmatized_text'])  \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(EXISTtraining['lemmatized_text']), maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(EXISTtesting['lemmatized_text']), maxlen=max_length, padding='post')\n",
    "\n",
    "y_train_task1 = np.array(EXISTtraining['task1'].map({'non-sexist': 0, 'sexist': 1}))\n",
    "y_test_task1 = np.array(EXISTtesting['task1'].map({'non-sexist': 0, 'sexist': 1}))\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "history = model.fit(X_train, y_train_task1, epochs=num_epochs, validation_data=(X_test, y_test_task1), batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, y_test_task1)\n",
    "print(\"Test Loss, Test Accuracy:\", results)\n",
    "\n",
    "precision = results[2]  \n",
    "recall = results[3]     \n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "print(f\"F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1718a83",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df026ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(EXISTtraining['task2'])\n",
    "y_test_encoded = label_encoder.transform(EXISTtesting['task2'])\n",
    "\n",
    "y_train_task2 = to_categorical(y_train_encoded)\n",
    "y_test_task2 = to_categorical(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task2 = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(6, activation='softmax') \n",
    "])\n",
    "\n",
    "model_task2.compile(\n",
    "    loss='categorical_crossentropy',  \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655da888",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "history_task2 = model_task2.fit(\n",
    "    X_train, y_train_task2, \n",
    "    epochs=num_epochs, \n",
    "    validation_data=(X_test, y_test_task2), \n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "results_task2 = model_task2.evaluate(X_test, y_test_task2)\n",
    "print(\"Task 2 - Test Loss, Test Accuracy:\", results_task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833868a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_task2 = model_task2.predict(X_test)\n",
    "y_pred_task2_classes = np.argmax(y_pred_task2, axis=1)\n",
    "y_true_task2_classes = np.argmax(y_test_task2, axis=1)\n",
    "\n",
    "print(classification_report(y_true_task2_classes, y_pred_task2_classes, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e514605",
   "metadata": {},
   "source": [
    "## 2nd attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12fdce",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 Add more dropout rate\n",
    "## 2 early stopping\n",
    "## 3 adjust patience parameter\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=4,          \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "vocab_size = 10000  # Vocabulary size\n",
    "max_length = 50     # Maximum length of the sequence\n",
    "embedding_dim = 64  # Dimensionality of the embedding vector\n",
    "oov_tok = \"<OOV>\"   # Out of vocabulary token\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(EXISTtraining['lemmatized_text'])  \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(EXISTtraining['lemmatized_text']), maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(EXISTtesting['lemmatized_text']), maxlen=max_length, padding='post')\n",
    "\n",
    "y_train_task1 = np.array(EXISTtraining['task1'].map({'non-sexist': 0, 'sexist': 1}))\n",
    "y_test_task1 = np.array(EXISTtesting['task1'].map({'non-sexist': 0, 'sexist': 1}))\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.6),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dropout(0.6),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_task1,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, y_test_task1),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, y_test_task1)\n",
    "print(\"Test Loss, Test Accuracy:\", results)\n",
    "\n",
    "precision = results[2]  \n",
    "recall = results[3]     \n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "print(f\"F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602980bc",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(EXISTtraining['task2'])\n",
    "y_test_encoded = label_encoder.transform(EXISTtesting['task2'])\n",
    "\n",
    "y_train_task2 = to_categorical(y_train_encoded)\n",
    "y_test_task2 = to_categorical(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task2 = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(6, activation='softmax')  \n",
    "])\n",
    "\n",
    "model_task2.compile(\n",
    "    loss='categorical_crossentropy',  \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "history_task2 = model_task2.fit(\n",
    "    X_train, y_train_task2, \n",
    "    epochs=num_epochs, \n",
    "    validation_data=(X_test, y_test_task2), \n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results_task2 = model_task2.evaluate(X_test, y_test_task2)\n",
    "print(\"Task 2 - Test Loss, Test Accuracy:\", results_task2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43218f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_task2 = model_task2.predict(X_test)\n",
    "y_pred_task2_classes = np.argmax(y_pred_task2, axis=1)\n",
    "y_true_task2_classes = np.argmax(y_test_task2, axis=1)\n",
    "\n",
    "print(classification_report(y_true_task2_classes, y_pred_task2_classes, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c616feb",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b964e",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109382d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4581026",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTtraining = EXISTtraining.dropna(subset=['lemmatized_text'])\n",
    "EXISTtesting = EXISTtesting.dropna(subset=['lemmatized_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf468cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000) \n",
    "X_train = vectorizer.fit_transform(EXISTtraining['lemmatized_text'])\n",
    "X_test = vectorizer.transform(EXISTtesting['lemmatized_text'])\n",
    "\n",
    "y_train_task1 = EXISTtraining['task1']\n",
    "y_test_task1 = EXISTtesting['task1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  \n",
    "    'gamma': [1, 0.1, 0.01, 0.001],  \n",
    "    'kernel': ['linear', 'rbf']  \n",
    "}\n",
    "\n",
    "svm_classifier = SVC(class_weight='balanced')\n",
    "\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, refit=True, verbose=2, cv=5, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train_task1) \n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_task1, y_pred))  \n",
    "print(\"Accuracy:\", accuracy_score(y_test_task1, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef935e",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    EXISTtraining['lemmatized_text'], \n",
    "    EXISTtraining['task2'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_svm.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fb286",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d985bbd",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e395d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "EXISTdata = pd.concat([EXISTtraining, EXISTtesting])\n",
    "\n",
    "X = EXISTdata['lemmatized_text']\n",
    "y = EXISTdata['task1'].map({'non-sexist': 0, 'sexist': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "grid_search = GridSearchCV(SVC(probability=True), param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_params = {'C': 1, 'gamma': 1, 'kernel': 'rbf'}  # Replace with actual best_params\n",
    "\n",
    "svm = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'], probability=True)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm), \n",
    "    ('rf', rf), \n",
    "    ('lr', lr)\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_voting = voting_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Voting Classifier - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "print(\"Voting Classifier - Accuracy:\", accuracy_score(y_test, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bc678",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = EXISTtraining['lemmatized_text']\n",
    "y = EXISTtraining['task2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Post-split - X_train:\", len(X_train), \"y_train:\", len(y_train))\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Post-resampling - X_train_res:\", X_train_res.shape, \"y_train_res:\", y_train_res.shape)\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('svm', svm), ('rf', rf), ('lr', lr)], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = voting_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be21ef",
   "metadata": {},
   "source": [
    "## Task 1 with tenfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "EXISTdata = pd.concat([EXISTtraining, EXISTtesting])\n",
    "\n",
    "X = EXISTdata['lemmatized_text']\n",
    "y = EXISTdata['task1'].map({'non-sexist': 0, 'sexist': 1})\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "svm = SVC(probability=True, C=1, gamma=1, kernel='rbf')\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm),\n",
    "    ('rf', rf),\n",
    "    ('lr', lr)\n",
    "], voting='soft')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('voting_clf', voting_clf)\n",
    "])\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1a8b3",
   "metadata": {},
   "source": [
    "## Task 2 with tenfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99befad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "X = EXISTtraining['lemmatized_text']\n",
    "y = EXISTtraining['task2']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm), \n",
    "    ('rf', rf), \n",
    "    ('lr', lr)\n",
    "], voting='soft')\n",
    "\n",
    "pipeline = make_pipeline(SMOTE(random_state=42), voting_clf)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(pipeline, X_tfidf, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Accuracy:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ef0ac",
   "metadata": {},
   "source": [
    "# Applying Ensemble model to G20 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cfc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "G20data = pd.read_csv('G20data_preprocessed.csv')\n",
    "print(G20data.head())\n",
    "\n",
    "print(G20data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "G20data = G20data.dropna(subset=['lemmatized_text'])\n",
    "\n",
    "G20_text_tfidf = vectorizer.transform(G20data['lemmatized_text'])\n",
    "\n",
    "G20data['predicted_sexist'] = voting_clf.predict(G20_text_tfidf)\n",
    "\n",
    "G20data['predicted_sexist'] = G20data['predicted_sexist'].map({0: 'non-sexist', 1: 'sexist'})\n",
    "\n",
    "print(G20data[['TweetContent', 'predicted_sexist']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9aaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G20data[['cleaned_text', 'lemmatized_text']].head())\n",
    "\n",
    "G20_text_tfidf = vectorizer.transform(G20data['lemmatized_text'])\n",
    "print(\"Shape of TF-IDF matrix:\", G20_text_tfidf.shape)\n",
    "\n",
    "predictions = voting_clf.predict(G20_text_tfidf)\n",
    "print(\"Sample predictions:\", predictions[:5])\n",
    "\n",
    "G20data['predicted_sexist'] = predictions\n",
    "print(\"NaNs in predictions:\", G20data['predicted_sexist'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G20data['predicted_sexist'] = predictions\n",
    "\n",
    "print(G20data[['TweetContent', 'predicted_sexist']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a291fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = G20data['predicted_sexist'].value_counts()\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "G20data.to_csv('G20_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29687373",
   "metadata": {},
   "source": [
    "# Comparing Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "G20data_results = pd.read_csv('G20_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "categories = {\n",
    "    \"ivanka_trump\": [\n",
    "        \"Ivanka Trump\", \"Ivanka\", \"Trump’s daughter\", \"Trump daughter\", \"Ivanka's\", \"IvankaTrump\", \"IvankaTrumps\", \"Trump's Daughter:\", \"nepotism\"\n",
    "    ],\n",
    "    \"angela_merkel\": [\n",
    "        \"Merkel\", \"Angela Merkel\", \"Merkel's\", \"Chancellor\", \"Angela Merkel's\", \"Angela's\", \"AngelaMerkel\", \"Angela\", \"merkels\", \"AngelaMerkels\", \"MerkelFail\", \"Mrrkel\"\n",
    "    ],\n",
    "    \"theresa_may\": [\n",
    "        \"Theresa May\", \"Theresa\", \"Theresa's\", \"Theresas\", \"Theresa May's\", \"Theresa May's\", \"UK Prime Minister\", \"UK PM\", \"TheresaMay\", \"TheresaMays\", \"Mrs. May\", \"theresa_may\", \"May\"\n",
    "    ],\n",
    "    \"erna_solberg\": [\n",
    "        \"Erna Solberg\", \"Erna Solberg's\", \"Erna's\", \"Solberg's\", \"Erna\", \"Solberg\", \"Solbergs\", \"Norwegian prime minister\", \"Norwegian PM\", \"ErnaSolberg\", \"ErnaSolbergs\"\n",
    "    ],\n",
    "    \"women\": [\n",
    "         \"EmpoweringWomen\", \"ladies\", \"lady\", \"Women\", \"women's\", \"woman\", \"woman's\", \"womens\", \"womans\", \"female\", \"females\", \"female's\", \"girl\", \"girl's\", \"Gender\", \"Feminism\", \"feminist\", \"'feminist's\", \"feminists\"\n",
    "    ],\n",
    "    \"we_fi\": [\n",
    "        \"Women Entrepreneurs Finance Initiative\", \"WeFi\", \"We-fi\", \"women’s fund\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "categories['all_four'] = list(set(categories['ivanka_trump'] + categories['angela_merkel'] + categories['theresa_may'] + categories['erna_solberg']))\n",
    "\n",
    "def create_regex_pattern(keywords):\n",
    "    pattern_parts = []\n",
    "    for keyword in keywords:\n",
    "        part = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "        pattern_parts.append(part)\n",
    "    return re.compile('|'.join(pattern_parts), re.IGNORECASE)\n",
    "\n",
    "# Apply categories to each tweet\n",
    "def categorize_tweet(tweet, regex_patterns):\n",
    "    categories_matched = {}\n",
    "    for category, pattern in regex_patterns.items():\n",
    "        if pattern.search(tweet):\n",
    "            categories_matched[category] = 1\n",
    "        else:\n",
    "            categories_matched[category] = 0\n",
    "    return pd.Series(categories_matched)\n",
    "\n",
    "regex_patterns = {category: create_regex_pattern(keywords) for category, keywords in categories.items()}\n",
    "\n",
    "G20data_results['TweetContent'] = G20data_results['TweetContent'].astype(str)  # Ensure text is in string format\n",
    "category_columns = G20data_results['TweetContent'].apply(categorize_tweet, regex_patterns=regex_patterns)\n",
    "\n",
    "G20data_results = pd.concat([G20data_results, category_columns], axis=1)\n",
    "\n",
    "print(G20data_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_category_keywords(text, keywords):\n",
    "    pattern = r'\\b(' + '|'.join([re.escape(kw) for kw in keywords]) + r')\\b'\n",
    "    return bool(re.search(pattern, text, flags=re.IGNORECASE))\n",
    "\n",
    "category_counts = {}\n",
    "\n",
    "for category, keywords in categories.items():\n",
    "    category_counts[category] = G20data_results['TweetContent'].apply(lambda x: count_category_keywords(x, keywords)).sum()\n",
    "\n",
    "category_counts_df = pd.DataFrame(list(category_counts.items()), columns=['Category', 'Count'])\n",
    "\n",
    "print(category_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "G20data_results.to_csv('G20_CAT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G20dataCAT = pd.read_csv('G20_CAT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00183c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexist_categories = ['ideological-inequality', 'misogyny-non-sexual-violence', 'objectification', 'sexual-violence', 'stereotyping-and-dominance']\n",
    "\n",
    "print(\"Distribution of predictions:\")\n",
    "print(G20dataCAT['predicted_sexist'].value_counts())\n",
    "\n",
    "sexist_tweet_counts = {}\n",
    "\n",
    "for category in categories:\n",
    "    filtered_data = G20dataCAT[(G20dataCAT[category] == 1) & (G20dataCAT['predicted_sexist'].isin(sexist_categories))]\n",
    "    count = filtered_data.shape[0]\n",
    "    sexist_tweet_counts[category] = count\n",
    "\n",
    "sexist_tweet_counts_df = pd.DataFrame(list(sexist_tweet_counts.items()), columns=['Category', 'Sexist Tweet Count'])\n",
    "print(\"\\nSexist Tweet Counts by Category:\")\n",
    "print(sexist_tweet_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f655c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tweet_counts = {}\n",
    "for category in categories:\n",
    "    total_tweet_counts[category] = G20dataCAT[G20dataCAT[category] == 1].shape[0]\n",
    "\n",
    "category_percentages = {}\n",
    "for category in categories:\n",
    "    if total_tweet_counts[category] > 0:  \n",
    "        percent = (sexist_tweet_counts[category] / total_tweet_counts[category]) * 100\n",
    "    else:\n",
    "        percent = 0  \n",
    "    category_percentages[category] = percent\n",
    "\n",
    "percentages_df = pd.DataFrame(list(category_percentages.items()), columns=['Category', 'Sexist Tweet Percentage'])\n",
    "print(\"\\nSexist Tweet Percentages by Category:\")\n",
    "print(percentages_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sexist_data = G20dataCAT[G20dataCAT['predicted_sexist'].isin(['ideological-inequality', 'sexual-violence', 'objectification', 'stereotyping-dominance', 'misogyny-non-sexual-violence'])]\n",
    "\n",
    "melted_data = sexist_data.melt(id_vars=['predicted_sexist'], value_vars=['all_four', 'ivanka_trump', 'angela_merkel', 'theresa_may', 'erna_solberg', 'women', 'we_fi'],\n",
    "                               var_name='Topic', value_name='Flag')\n",
    "\n",
    "filtered_melted_data = melted_data[melted_data['Flag'] == 1]\n",
    "\n",
    "pivot_table = filtered_melted_data.pivot_table(index='Topic', columns='predicted_sexist', aggfunc='size', fill_value=0)\n",
    "\n",
    "print(pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topic_sums = pivot_table.sum(axis=1)\n",
    "\n",
    "pivot_percentage = pivot_table.div(topic_sums, axis=0) * 100\n",
    "\n",
    "print(pivot_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0573f94",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca05fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "categories = ['Sexual Violence', 'Ideological Inequality', 'Stereotyping and Dominance', 'Misogyny and Non-Sexual Violence', 'Objectification']\n",
    "values = [78, 25, 15, 8, 4]\n",
    "\n",
    "df_new = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Count': values\n",
    "})\n",
    "\n",
    "df_sorted_new = df_new.sort_values('Count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "bar_plot_new = sns.barplot(\n",
    "    x='Category', \n",
    "    y='Count', \n",
    "    data=df_sorted_new, \n",
    "    color='royalblue'  \n",
    ")\n",
    "\n",
    "\n",
    "for p in bar_plot_new.patches:\n",
    "    height = p.get_height()    \n",
    "    plt.text(p.get_x() + p.get_width() / 2,  \n",
    "             height + 1,  \n",
    "             '{:1.0f}'.format(height),  \n",
    "             ha='center', va='bottom', fontsize=15)  \n",
    "\n",
    "def wrap_labels(labels, width=15):\n",
    "    return [textwrap.fill(label, width) for label in labels]\n",
    "\n",
    "wrapped_labels = wrap_labels(df_sorted_new['Category'], width=15)\n",
    "bar_plot_new.set_xticks(range(len(wrapped_labels)))  \n",
    "bar_plot_new.set_xticklabels(wrapped_labels, fontsize=15, ha='center')\n",
    "\n",
    "for label in bar_plot_new.get_xticklabels():\n",
    "    label.set_rotation(0)  \n",
    "    label.set_ha('center')  \n",
    "    label.set_va('bottom') \n",
    "    label.set_y(-0.1)  \n",
    "\n",
    "plt.subplots_adjust(bottom=0.25) \n",
    "\n",
    "plt.title('Distribution of Tweets Across Sexist Categories', fontsize=17)\n",
    "plt.xlabel('Categories',fontsize=17, labelpad=20)\n",
    "plt.ylabel('Number of Instances', fontsize=17)\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
